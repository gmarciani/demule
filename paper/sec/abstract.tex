\begin{abstract}

  % %
  % MOTIVATION
  % %
  Modern software applications process massive amounts of data under stringent timing constraints.
  %
  The advances in HPC make technologies such as OpenMP and CUDA really attractive to boost performance of complex algorithms.
  %
  % %
  % PROBLEM STATEMENT
  % %
  In this context, deep learning and prefix-sum operations provide a great benchmark to exploit HPC.

  % %
  % APPROACH
  % %
  In this technical report we propose massively parallel implementations of two serial-born pieces of software, written in C.
  %
  First, we propose an OpenMP and CUDA implementation of a deep learning algorithm for hand-written digits recognition leveraging the back-propagation.
  %
  Then, we propose a CUDA implementation of the prefix-sum operation over a vector of integers.

  % %
  % RESULTS
  % %
  The experimental results show that about neural networks show a speed-up of~$\sim \! 1300\%$ for the OpenMP and~$\sim \! 1380\%$ for CUDA implementation, with respect to the serial counterpart.
  %
  On the other hand, the experimental results about prefix-sum show a good scaling with respect to the increasing
  input size; they show, nonetheless, an efficient use of the GPU resources.
  %
  % %
  % CONCLUSIONS
  % %
  Although the promising results, we conclude our work delineating possible improvements for our model.

\end{abstract}
